{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9i0I-KIVpyHB",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "zSMMPILBpyHF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import gc\n",
    "import sys\n",
    "import sklearn\n",
    "import scipy\n",
    "import xlearn as xl\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.3f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKmNAlq7DT4U",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "3Q300Q_mpyHL"
   },
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    columns_to_use = [\n",
    "        \"date_time\",\n",
    "        \"zone_id\",\n",
    "        \"banner_id\",\n",
    "        \"campaign_clicks\",\n",
    "        \"os_id\",\n",
    "        \"country_id\",\n",
    "        \"impressions\",\n",
    "        \"clicks\",\n",
    "        \"oaid_hash\",\n",
    "    ]\n",
    "    categorical_columns = [\n",
    "        \"zone_id\",\n",
    "        \"banner_id\",\n",
    "        \"os_id\",\n",
    "        \"country_id\",\n",
    "        \"impressions\",\n",
    "        \"clicks\",\n",
    "    ]\n",
    "    data = pd.read_csv(data_path, usecols=columns_to_use, parse_dates=[\"date_time\"])\n",
    "    data[categorical_columns].astype(\"category\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "sQRWkg2SuNyu"
   },
   "outputs": [],
   "source": [
    "def group_categories(data, column_names, threshold):\n",
    "    for column in column_names:\n",
    "        new_value = data[column].max() + 1000\n",
    "        categories_to_group = data[column].value_counts(normalize=True) < threshold\n",
    "        categories_to_group = categories_to_group[categories_to_group].index\n",
    "        data.loc[data[column].isin(categories_to_group), column] = new_value\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rDWg0rGgWqNc"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(data, interactions=None):\n",
    "    # Удалим столбец impressions\n",
    "    data.drop([\"impressions\"], axis=1, inplace=True)\n",
    "\n",
    "    # Временные признаки\n",
    "    data[\"hour\"] = data.date_time.dt.hour\n",
    "    data[\"weekday\"] = data.date_time.dt.weekday\n",
    "\n",
    "    # Группировка редких категорий в banner_id, zone_id, oaid_hash\n",
    "    data = group_categories(data, [\"banner_id\", \"zone_id\"], 0.001)\n",
    "    oaid_hash_vc = data.oaid_hash.value_counts()\n",
    "    oaid_hash_to_change = oaid_hash_vc[oaid_hash_vc <= 2].index\n",
    "    data.loc[data.oaid_hash.isin(oaid_hash_to_change), \"oaid_hash\"] = -100\n",
    "\n",
    "    # Нормировка campaign_clicks\n",
    "    data[\"campaign_clicks\"] = np.log1p(data.campaign_clicks + 1)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "lB7lx7FxT5nM"
   },
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "    ts = pd.Timestamp(\"2021-10-02 00:00:00\")\n",
    "    data.sort_values(by=\"date_time\", inplace=True)\n",
    "    train_mask, test_mask = data.date_time < ts, data.date_time >= ts\n",
    "    X_train, X_test = data[train_mask].copy(), data[test_mask].copy()\n",
    "    y_train, y_test = X_train.clicks.to_numpy(), X_test.clicks.to_numpy()\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCg5JscypyHH"
   },
   "source": [
    "## Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9xap2hkpyHK"
   },
   "source": [
    "**Этап 1:** загрузим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yQF4XaeCpyHL",
    "outputId": "5707d835-8753-45b4-9a1d-b50d9aacb6fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>zone_id</th>\n",
       "      <th>banner_id</th>\n",
       "      <th>oaid_hash</th>\n",
       "      <th>campaign_clicks</th>\n",
       "      <th>os_id</th>\n",
       "      <th>country_id</th>\n",
       "      <th>impressions</th>\n",
       "      <th>clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-27 00:01:30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5664530014561852622</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-09-26 22:54:49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5186611064559013950</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-09-26 23:57:20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2215519569292448030</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-09-27 00:04:30</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6262169206735077204</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-27 00:06:21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4778985830203613115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            date_time  zone_id  banner_id            oaid_hash  \\\n",
       "0 2021-09-27 00:01:30        0          0  5664530014561852622   \n",
       "1 2021-09-26 22:54:49        1          1  5186611064559013950   \n",
       "2 2021-09-26 23:57:20        2          2  2215519569292448030   \n",
       "3 2021-09-27 00:04:30        3          3  6262169206735077204   \n",
       "4 2021-09-27 00:06:21        4          4  4778985830203613115   \n",
       "\n",
       "   campaign_clicks  os_id  country_id  impressions  clicks  \n",
       "0                0      0           0            1       1  \n",
       "1                0      0           1            1       1  \n",
       "2                3      0           0            1       1  \n",
       "3                0      1           1            1       1  \n",
       "4                0      1           0            1       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"data.csv\"\n",
    "data = load_data(data_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWMCh1qxn5KE"
   },
   "source": [
    "**Этап 2:** анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emG3zw6Thd8Q"
   },
   "source": [
    "Так как данные у нас не поменялись, за исключением нового столбца - `oaid_hash`, проанализируем только его"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zBjGVlxnjjjt"
   },
   "outputs": [],
   "source": [
    "def oaid_hash_analysis(data):\n",
    "    vc = data.oaid_hash.value_counts()\n",
    "    vc.reset_index(inplace=True, drop=True)\n",
    "    vc.plot(figsize=(8, 4), xlabel=\"oaid_hash\", ylabel=\"value counts\", grid=True)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Уникальных категорий в столбце: {len(data.oaid_hash.unique())}\\n\")\n",
    "    print(\n",
    "        f\"Доля пользователей, для которых всего 1 наблюдение в датасете: {(vc == 1).sum() / len(vc):.3f}\\n\"\n",
    "    )\n",
    "    print(\"Доля пользователей, для которых всего k наблюдений в датасете:\\n\")\n",
    "    print(vc.value_counts(normalize=True)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "id": "2k9YoL_Rn2R7",
    "outputId": "a467a87f-707b-4364-a1ea-f6f91a836cf1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Уникальных категорий в столбце: 6510316\n",
      "\n",
      "Доля пользователей, для которых всего 1 наблюдение в датасете: 0.642\n",
      "\n",
      "Доля пользователей, для которых всего k наблюдений в датасете:\n",
      "\n",
      "1    0.642\n",
      "2    0.161\n",
      "3    0.066\n",
      "4    0.036\n",
      "5    0.022\n",
      "6    0.015\n",
      "7    0.010\n",
      "8    0.008\n",
      "9    0.006\n",
      "10   0.005\n",
      "Name: oaid_hash, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11741/2664417664.py:10: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(vc.value_counts(normalize=True)[:10])\n"
     ]
    }
   ],
   "source": [
    "oaid_hash_analysis(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1V8yEAYKjBfN"
   },
   "source": [
    "Видно, что распределение сильно ассиметричное, очень много пользователей, для которых всего лишь одно или два наблюдения, что будет вносить шум в модель, поэтому объединим таких пользователей в отдельную категорию (`k = 1`, `k = 2`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s46hUhPwK7Ih",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n3ci0-Ojmbhg"
   },
   "source": [
    "***Фичи, которые будем использовать:***\n",
    "1. banner_id\n",
    "2. zone_id\n",
    "3. hour\n",
    "4. weekday\n",
    "5. country_id\n",
    "6. oaid_hash\n",
    "7. os_id\n",
    "8. log campaign_clicks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tIhgcbdYO0Ch"
   },
   "outputs": [],
   "source": [
    "data = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for training with xlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FB9b5l-MGpXG"
   },
   "source": [
    "Для обучения `field aware factorization machine` будем использовать пакет `xlearn`. Для того, чтобы что-то обучалось, необходимо привести данные к определенному формату: датасеты - трейн, валидация и тест - сохраняются в файлики `.txt`. Сначала сохраним данные в разреженные матрицы, чтобы предобработка данных прошла чуть быстрее.\n",
    "\n",
    "В этот раз сделаем обычную  валидацию. `One-Hot` энкодер фиттится только на трейне, чтобы не было утечки информации в тест. Если энкодер встретит в тесте что-то непонятное для него, он пропустит такое наблюдение.\n",
    "\n",
    "Функции не выношу наверх, чтобы было понятно, что происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DnWX73MDHk-6"
   },
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = [\n",
    "    \"banner_id\",\n",
    "    \"zone_id\",\n",
    "    \"hour\",\n",
    "    \"weekday\",\n",
    "    \"country_id\",\n",
    "    \"oaid_hash\",\n",
    "    \"os_id\",\n",
    "]\n",
    "NUMERICAL_FEATURES = [\"campaign_clicks\"]\n",
    "ALL_FEATURES = CATEGORICAL_FEATURES + NUMERICAL_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "sWKbVNmkdL8-"
   },
   "outputs": [],
   "source": [
    "def create_sparse_matrix(data, encoder):\n",
    "    sparse_cat = encoder.transform(data[CATEGORICAL_FEATURES])\n",
    "    sparse_num = csr_matrix(data[NUMERICAL_FEATURES])\n",
    "\n",
    "    fields = np.arange(sparse_cat.shape[1] + len(NUMERICAL_FEATURES))\n",
    "    cur_code = 0\n",
    "    h = np.hstack(([0], np.cumsum(encoder._n_features_outs)))\n",
    "    for i in range(1, len(h)):\n",
    "        fields[h[i - 1] : h[i]] = cur_code\n",
    "        cur_code += 1\n",
    "\n",
    "    for i in range(len(NUMERICAL_FEATURES), 0, -1):\n",
    "        fields[-i] = cur_code\n",
    "        cur_code += 1\n",
    "\n",
    "    csr = scipy.sparse.hstack((sparse_cat, sparse_num))\n",
    "    return csr, fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "2MMKAvHJJRYJ"
   },
   "outputs": [],
   "source": [
    "def prepare_data_for_libffm(data):\n",
    "    print(\"Preparing the data...\\n\")\n",
    "    # Делим датасет на трейн и тест\n",
    "    X_train, y_train, X_test, y_test = train_test_split(data)\n",
    "\n",
    "    # Зафиттим энкодер только на трейне и запомним его, чтобы использовать на тесте\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True)\n",
    "    encoder.fit(X_train[CATEGORICAL_FEATURES])\n",
    "\n",
    "    # Делим трейн на трейн и валидацию\n",
    "    train_ids = np.arange(len(X_train))\n",
    "    train_ids, val_ids = sklearn.model_selection.train_test_split(\n",
    "        train_ids, test_size=0.2, stratify=y_train\n",
    "    )\n",
    "    X_val, y_val = X_train.iloc[val_ids], y_train[val_ids]\n",
    "    X_train, y_train = X_train.iloc[train_ids], y_train[train_ids]\n",
    "\n",
    "    assert (\n",
    "        X_train.shape[0] == y_train.shape[0]\n",
    "    ), \"The dimensions of the dataset and labels do not match\"\n",
    "    assert (\n",
    "        X_val.shape[0] == y_val.shape[0]\n",
    "    ), \"The dimensions of the dataset and labels do not match\"\n",
    "\n",
    "    print(\"Number of observations in datasets:\")\n",
    "    print(f\"train:      {X_train.shape[0]}\")\n",
    "    print(f\"validation: {X_val.shape[0]}\")\n",
    "    print(f\"test:       {X_test.shape[0]}\\n\")\n",
    "\n",
    "    # Создаем разреженные матрицы и поля\n",
    "    X_train_sparse, train_fields = create_sparse_matrix(X_train, encoder)\n",
    "    X_val_sparse, val_fields = create_sparse_matrix(X_val, encoder)\n",
    "    X_test_sparse, test_fields = create_sparse_matrix(X_test, encoder)\n",
    "\n",
    "    assert X_train_sparse.shape[1] == len(\n",
    "        train_fields\n",
    "    ), \"Each feature must have a field defined!\"\n",
    "    assert X_val_sparse.shape[1] == len(\n",
    "        val_fields\n",
    "    ), \"Each feature must have a field defined!\"\n",
    "    assert X_test_sparse.shape[1] == len(\n",
    "        test_fields\n",
    "    ), \"Each feature must have a field defined!\"\n",
    "\n",
    "    num_features = len(NUMERICAL_FEATURES) + len(CATEGORICAL_FEATURES)\n",
    "    assert (\n",
    "        len(X_train_sparse.nonzero()[0]) == len(X_train) * num_features\n",
    "    ), \"Something is wrong...\"\n",
    "    assert (\n",
    "        len(X_val_sparse.nonzero()[0]) == len(X_val) * num_features\n",
    "    ), \"Something is wrong...\"\n",
    "    assert X_train_sparse.shape[1] == X_val_sparse.shape[1] == X_test_sparse.shape[1]\n",
    "\n",
    "    print(f\"Total number of features: {X_train_sparse.shape[1]}\")\n",
    "    matrices = [X_train_sparse, X_val_sparse, X_test_sparse]\n",
    "    fields = [train_fields, val_fields, test_fields]\n",
    "    ys = [y_train, y_val, y_test]\n",
    "    \n",
    "    print(\"Done!\")\n",
    "    return matrices, fields, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XuBSLoYQNOGj"
   },
   "outputs": [],
   "source": [
    "def convert_to_libffm(X, y, fields, out_path):\n",
    "    \"\"\"\n",
    "    Function which helps to get file with rows like this:\n",
    "     <label> <field1>:<feature1>:<value1> <field2>:<feature2>:<value2>\n",
    "    \"\"\"\n",
    "    \n",
    "    values = X.data\n",
    "    rows, cols = X.nonzero()\n",
    "    with open(out_path, \"w\") as file:\n",
    "        cur_obs = rows[0]\n",
    "        file.write(f\"{y[cur_obs]}\")\n",
    "        for obs, feature, value in zip(rows, cols, values):\n",
    "            if obs == cur_obs:\n",
    "                file.write(f\" {fields[feature]}:{feature}:{value}\")\n",
    "            else:\n",
    "                cur_obs = obs\n",
    "                file.write(\"\\n\")\n",
    "                file.write(f\"{y[cur_obs]}\")\n",
    "                file.write(f\" {fields[feature]}:{feature}:{value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Приступаем к делу: нам необходимо получить фичи, поле для каждой фичи и лейблы для каждого наблюдения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gyw4A_Tfx1zc",
    "outputId": "a76ab4e3-d343-471f-ac40-fdce8f164dc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing the data...\n",
      "\n",
      "Number of observations in datasets:\n",
      "train:      10953995\n",
      "validation: 2738499\n",
      "test:       2128978\n",
      "\n",
      "Total number of features: 1170867\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "matrices, fields, ys = prepare_data_for_libffm(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраняем наши данные в файлы, которые далее будем использовать при обучении и тестировании"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6l2YH7bO2W6I"
   },
   "outputs": [],
   "source": [
    "out_names = [\"train.txt\", \"val.txt\", \"test.txt\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hv9VKqC8xV5I",
    "outputId": "7594359b-4528-40a7-b007-4c2bab556e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting to train.txt...\n",
      "Convertion to train.txt is completed!\n",
      "\n",
      "Converting to val.txt...\n",
      "Convertion to val.txt is completed!\n",
      "\n",
      "Converting to test.txt...\n",
      "Convertion to test.txt is completed!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, X, field, y in zip(out_names, matrices, fields, ys):\n",
    "    print(f\"Converting to {name}...\")\n",
    "    convert_to_libffm(X, y, field, name)\n",
    "    print(f\"Convertion to {name} is completed!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing FFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучать модельки и перебирать гиперпараметры: коэффициент регуляризации и размерность для FFM. К сожалению, почему-то при переборе всех гиперпараметров в едином цикле ядро падает из-за нехватки памяти, даже при условии использования сборщика мусора. Поэтому придется руками обучать модели для каждой комбинации гиперпараметров :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lambda\": [0.00001, 0.0001, 0.001, 0.01, 0.1], \"dim\": [4, 8, 12, 16]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(param, model_prefix):\n",
    "    print(f\"Training with parameters: {model_prefix}\\n\")\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(\"train.txt\")\n",
    "    ffm_model.setValidate(\"val.txt\")\n",
    "    ffm_model.fit(param, f\"models/{model_prefix}.out\")\n",
    "    return f\"models/{model_prefix}.out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(path_to_model, model_prefix, y_test):\n",
    "    print(f\"Testing {model_prefix}\\n\")\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setSigmoid()\n",
    "    ffm_model.setTest(\"test.txt\")\n",
    "    pred_path = f\"predictions/{model_prefix}.out\"\n",
    "    ffm_model.predict(path_to_model, pred_path)\n",
    "\n",
    "    pred = np.genfromtxt(pred_path, dtype=float)\n",
    "    res = {\"log_loss\": log_loss(y_test, pred), \"roc_auc\": roc_auc_score(y_test, pred)}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Lots of output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=1e-05, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.77 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 294.79 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.32 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.102566            0.098579                4.08\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.092683            0.092785                3.84\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.083777            0.091298                3.84\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.078242            0.091555                4.22\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.074641            0.092349                4.01\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.071918            0.093279                3.75\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best loss: 0.091298\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=1e-05, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.38 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 33.60 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=1e-05, dim=4.out'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.00001\n",
    "dim = 4\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=1e-05, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.26 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 580.65 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.59 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.101987            0.097268                4.39\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.091084            0.092049                4.16\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.082476            0.091163                4.11\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.077345            0.091667                4.17\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.073823            0.092600                4.34\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.070959            0.093716                4.41\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best loss: 0.091163\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=1e-05, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.71 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 35.83 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=1e-05, dim=8.out'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.00001\n",
    "dim = 8\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=1e-05, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.03 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 866.50 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.90 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.101588            0.096606                5.01\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.090366            0.091947                5.02\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.082113            0.091216                4.91\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.077093            0.091677                5.16\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.073411            0.092633                5.13\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.070223            0.093872                4.87\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best loss: 0.091216\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=1e-05, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.11 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 40.15 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=1e-05, dim=12.out'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.00001\n",
    "dim = 12\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=1e-05, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.19 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.13 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.21 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.101083            0.096006                5.53\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.089495            0.091782                6.18\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.081479            0.091234                5.45\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.076621            0.091904                5.52\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.073027            0.092860                5.52\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.069831            0.094083                5.70\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 3, best loss: 0.091234\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=1e-05, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.56 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 46.09 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=1e-05, dim=16.out'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.00001\n",
    "dim = 16\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.0001, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.94 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 294.79 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.29 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.104000            0.102380                3.74\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.100133            0.099511                3.74\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.096351            0.097034                3.88\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.092522            0.094956                3.78\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.088955            0.093561                3.94\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.085968            0.092718                3.76\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.083532            0.092177                3.67\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.081487            0.091888                3.61\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.079752            0.091741                3.77\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.078255            0.091685                3.82\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.0001, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.37 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 47.85 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.0001, dim=4.out'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.0001\n",
    "dim = 4\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.0001, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.93 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 580.65 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.58 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.103765            0.101943                4.11\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.099293            0.098669                4.16\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.094982            0.095999                4.39\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.090862            0.094174                4.43\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.087420            0.093071                4.74\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.084696            0.092423                5.07\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.082446            0.092077                5.32\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.080543            0.091863                5.05\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.078904            0.091810                4.66\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.077465            0.091811                4.54\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 9, best loss: 0.091810\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.0001, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.70 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 55.64 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.0001, dim=8.out'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.0001\n",
    "dim = 8\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.0001, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.86 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 866.50 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.87 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.103770            0.101931                4.74\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.099353            0.098734                4.69\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.095196            0.096173                4.76\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.091103            0.094233                4.75\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.087578            0.093071                4.75\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.084715            0.092410                4.76\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.082376            0.092009                4.72\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.080390            0.091831                4.81\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.078688            0.091786                4.74\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.077209            0.091803                4.78\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 9, best loss: 0.091786\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.0001, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.01 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.0001, dim=12.out'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m[------------] Total time cost: 57.61 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "reg_lambda = 0.0001\n",
    "dim = 12\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.0001, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.78 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.13 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.16 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.103665            0.101749                5.28\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.099026            0.098470                5.22\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.094699            0.095800                5.25\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.090516            0.093985                5.30\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.087036            0.092942                5.24\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.084280            0.092327                5.26\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.082013            0.092030                5.23\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.080100            0.091832                5.26\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.078456            0.091813                5.32\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.077010            0.091870                5.28\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Early-stopping at epoch 9, best loss: 0.091813\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.0001, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.40 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 63.75 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.0001, dim=16.out'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.0001\n",
    "dim = 16\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.001, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.80 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 294.79 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.30 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.107161            0.106441                3.53\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.105643            0.105598                3.50\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104511            0.104798                3.51\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103502            0.104072                3.51\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.102535            0.103458                3.52\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.101612            0.102849                3.54\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.100746            0.102234                3.60\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.099890            0.101727                3.53\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.099069            0.101239                3.53\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.098291            0.100741                3.54\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.001, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.35 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 43.29 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.001, dim=4.out'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.001\n",
    "dim = 4\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.001, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.72 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 580.65 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.58 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.107130            0.106454                4.21\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.105645            0.105578                4.22\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104505            0.104747                4.17\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103439            0.104048                4.18\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.102445            0.103357                4.21\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.101510            0.102703                4.22\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.100604            0.102165                4.18\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.099758            0.101597                4.20\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.098921            0.101109                4.16\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.098123            0.100601                4.25\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.001, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.69 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 50.93 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.001, dim=8.out'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.001\n",
    "dim = 8\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.001, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 866.50 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.91 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.107133            0.106472                5.16\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.105650            0.105597                4.89\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104505            0.104742                4.81\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103436            0.104041                4.78\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.102428            0.103362                4.78\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.101489            0.102671                5.43\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.100575            0.102095                5.38\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.099700            0.101579                5.06\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.098868            0.101062                4.97\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.098060            0.100557                4.90\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.001, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.09 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 60.56 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.001, dim=12.out'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.001\n",
    "dim = 12\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.001, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.06 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.13 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.17 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.107138            0.106433                5.26\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.105637            0.105595                5.26\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.104482            0.104760                5.27\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.103423            0.103959                5.34\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.102407            0.103332                5.30\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.101447            0.102712                5.33\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.100549            0.102076                5.33\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.099664            0.101542                5.37\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.098811            0.101069                5.36\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.098002            0.100532                5.43\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.001, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.38 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 64.65 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.001, dim=16.out'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.001\n",
    "dim = 16\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.01, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.71 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 294.79 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.29 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.111883            0.111496                3.58\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.110712            0.110812                3.54\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.109843            0.110224                3.59\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.109122            0.109815                3.58\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.108478            0.109428                3.55\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.107918            0.109034                3.55\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.107388            0.108753                3.63\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.106917            0.108402                3.58\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.106473            0.108168                3.57\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.106065            0.107900                3.64\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.01, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.35 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 43.65 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.01, dim=4.out'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.01\n",
    "dim = 4\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.01, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.72 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 580.65 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.60 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.111879            0.111560                4.32\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.110703            0.110856                4.28\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.109838            0.110211                4.26\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.109101            0.109831                4.24\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.108469            0.109448                4.30\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.107905            0.109028                4.27\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.107384            0.108717                4.24\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.106907            0.108444                4.39\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.106467            0.108191                4.30\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.106058            0.107912                4.28\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.01, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.70 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 51.85 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.01, dim=8.out'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.01\n",
    "dim = 8\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.01, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.25 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 866.50 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.94 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.111871            0.111550                5.58\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.110709            0.110805                5.72\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.109832            0.110308                5.62\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.109119            0.109791                5.65\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.108475            0.109422                5.70\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.107904            0.109059                5.79\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.107389            0.108731                5.62\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.106909            0.108474                5.72\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.106470            0.108171                5.62\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.106055            0.107923                5.87\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.01, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.23 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 68.92 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.01, dim=12.out'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.01\n",
    "dim = 12\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.01, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.84 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.13 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.20 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.111880            0.111521                5.71\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.110705            0.110779                5.78\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.109838            0.110268                5.55\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.109109            0.109813                5.77\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.108473            0.109414                5.41\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.107907            0.109061                5.49\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.107388            0.108728                5.48\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.106914            0.108409                5.66\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.106466            0.108172                6.14\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.106052            0.107945                5.96\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.01, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.72 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 70.16 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.01, dim=16.out'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.01\n",
    "dim = 16\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.1, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 8.30 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 294.79 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.29 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.116859            0.116233                3.60\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.115977            0.115817                3.58\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.115335            0.115478                3.52\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.114893            0.115217                3.56\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.114548            0.115049                3.55\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.114219            0.114854                3.54\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.113930            0.114730                3.57\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.113687            0.114622                3.54\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.113523            0.114475                3.56\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.113288            0.114395                3.53\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.1, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.34 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 44.98 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.1, dim=4.out'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "dim = 4\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.1, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.03 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 580.65 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.58 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.116894            0.116254                4.32\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.115993            0.115736                4.33\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.115414            0.115453                4.24\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.114910            0.115248                4.24\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.114562            0.115020                4.30\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.114224            0.114851                4.30\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.113978            0.114687                4.25\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.113699            0.114573                4.27\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.113522            0.114468                4.30\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.113320            0.114371                4.31\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.1, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.69 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 52.10 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.1, dim=8.out'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "dim = 8\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.1, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 6.84 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 866.50 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.87 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.116839            0.116288                4.95\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.115954            0.115807                4.89\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.115369            0.115442                4.90\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.114919            0.115253                4.91\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.114525            0.115040                4.92\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.114207            0.114856                4.91\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.113935            0.114718                4.88\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.113753            0.114615                4.96\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.113488            0.114484                4.99\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.113312            0.114414                4.99\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.1, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.04 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 59.42 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.1, dim=12.out'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "dim = 12\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with parameters: lambda=0.1, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (val.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.39 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 1.13 GB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 1.22 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss       Test log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.116901            0.116260                5.49\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.115933            0.115838                5.41\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.115388            0.115484                5.39\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.114897            0.115284                5.42\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.114520            0.115032                5.42\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.114225            0.114833                5.41\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.113989            0.114727                5.38\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.113731            0.114560                5.43\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.113499            0.114505                5.38\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.113300            0.114355                5.46\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/lambda=0.1, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 1.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 66.29 (sec)\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'models/lambda=0.1, dim=16.out'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_lambda = 0.1\n",
    "dim = 16\n",
    "\n",
    "model_prefix = f\"lambda={reg_lambda}, dim={dim}\"\n",
    "param = {\"task\": \"binary\", \"lambda\": reg_lambda, \"k\": dim}\n",
    "train_model(param, model_prefix=f\"lambda={reg_lambda}, dim={dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test our models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(params):\n",
    "    result = {}\n",
    "    for reg_coef, dim in product(params[\"lambda\"], params[\"dim\"]):\n",
    "        prefix = f\"lambda={reg_coef}, dim={dim}\"\n",
    "        name = f\"models/{prefix}.out\"\n",
    "        prefix = f\"lambda={reg_coef}, dim={dim}\"\n",
    "        result[f\"({reg_coef}, {dim})\"] = test_model(name, prefix, y_test)\n",
    "\n",
    "    with open(\"result.pkl\", \"wb\") as f:\n",
    "        pickle.dump(result, f)\n",
    "\n",
    "    return (\n",
    "        pd.DataFrame.from_dict(result)\n",
    "        .transpose()\n",
    "        .sort_values(by=[\"roc_auc\"], ascending=False)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"lambda\": [0.00001, 0.0001, 0.001, 0.01, 0.1], \"dim\": [4, 8, 12, 16]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing lambda=1e-05, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=1e-05, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.37 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.81 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.127507\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.30 (sec)\u001b[0m\n",
      "Testing lambda=1e-05, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=1e-05, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 8\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.63 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.56 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.130938\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.35 (sec)\u001b[0m\n",
      "Testing lambda=1e-05, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=1e-05, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 12\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.96 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.49 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.129825\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.67 (sec)\u001b[0m\n",
      "Testing lambda=1e-05, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=1e-05, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 16\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.77 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.49 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.131251\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.50 (sec)\u001b[0m\n",
      "Testing lambda=0.0001, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.0001, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.32 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.127657\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 1.95 (sec)\u001b[0m\n",
      "Testing lambda=0.0001, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.0001, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 8\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.61 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.49 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.128978\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.29 (sec)\u001b[0m\n",
      "Testing lambda=0.0001, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.0001, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 12\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.92 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.49 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.129162\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.62 (sec)\u001b[0m\n",
      "Testing lambda=0.0001, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.0001, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 16\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.35 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.55 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.129109\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 3.17 (sec)\u001b[0m\n",
      "Testing lambda=0.001, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.001, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.35 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.131471\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.01 (sec)\u001b[0m\n",
      "Testing lambda=0.001, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.001, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 8\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.65 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.131378\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.34 (sec)\u001b[0m\n",
      "Testing lambda=0.001, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.001, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 12\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.00 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.51 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.131366\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.70 (sec)\u001b[0m\n",
      "Testing lambda=0.001, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.001, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 16\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.28 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.56 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.131406\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 3.08 (sec)\u001b[0m\n",
      "Testing lambda=0.01, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.01, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.34 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.51 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.141152\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 1.94 (sec)\u001b[0m\n",
      "Testing lambda=0.01, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.01, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 8\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.64 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.141191\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.26 (sec)\u001b[0m\n",
      "Testing lambda=0.01, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.01, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 12\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.98 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.141281\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.68 (sec)\u001b[0m\n",
      "Testing lambda=0.01, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.01, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 16\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.30 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.51 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.141402\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 3.03 (sec)\u001b[0m\n",
      "Testing lambda=0.1, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.1, dim=4.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.36 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.150778\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 1.94 (sec)\u001b[0m\n",
      "Testing lambda=0.1, dim=8\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.1, dim=8.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 8\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.68 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.50 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.150731\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.32 (sec)\u001b[0m\n",
      "Testing lambda=0.1, dim=12\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.1, dim=12.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 12\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.99 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.51 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.150671\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 2.67 (sec)\u001b[0m\n",
      "Testing lambda=0.1, dim=16\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/lambda=0.1, dim=16.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 16\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 1.29 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.49 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.150911\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 3.05 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "result = get_result(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(0.0001, 4)</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1e-05, 4)</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0001, 8)</th>\n",
       "      <td>0.129</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0001, 16)</th>\n",
       "      <td>0.129</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1e-05, 8)</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.0001, 12)</th>\n",
       "      <td>0.129</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1e-05, 12)</th>\n",
       "      <td>0.130</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(1e-05, 16)</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.001, 16)</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.001, 8)</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.001, 4)</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.001, 12)</th>\n",
       "      <td>0.131</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.01, 8)</th>\n",
       "      <td>0.141</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.01, 12)</th>\n",
       "      <td>0.141</td>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.01, 4)</th>\n",
       "      <td>0.141</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.01, 16)</th>\n",
       "      <td>0.141</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 4)</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 12)</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 16)</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.1, 8)</th>\n",
       "      <td>0.151</td>\n",
       "      <td>0.774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              log_loss  roc_auc\n",
       "(0.0001, 4)      0.128    0.804\n",
       "(1e-05, 4)       0.128    0.803\n",
       "(0.0001, 8)      0.129    0.800\n",
       "(0.0001, 16)     0.129    0.799\n",
       "(1e-05, 8)       0.131    0.799\n",
       "(0.0001, 12)     0.129    0.798\n",
       "(1e-05, 12)      0.130    0.798\n",
       "(1e-05, 16)      0.131    0.795\n",
       "(0.001, 16)      0.131    0.792\n",
       "(0.001, 8)       0.131    0.792\n",
       "(0.001, 4)       0.131    0.792\n",
       "(0.001, 12)      0.131    0.792\n",
       "(0.01, 8)        0.141    0.776\n",
       "(0.01, 12)       0.141    0.776\n",
       "(0.01, 4)        0.141    0.775\n",
       "(0.01, 16)       0.141    0.775\n",
       "(0.1, 4)         0.151    0.775\n",
       "(0.1, 12)        0.151    0.774\n",
       "(0.1, 16)        0.151    0.774\n",
       "(0.1, 8)         0.151    0.774"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, получили лучший результат как и по `log_loss`, так и по `roc_auc` со следующими параметрами:\n",
    "1. Коэффициент регуляризации - 0.0001\n",
    "2. Размерность векторов - 4\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training best model: lambda=0.0001, dim=4\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[35m\u001b[1m[ WARNING    ] Validation file not found, xLearn has already disable early-stopping.\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for training task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (train.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of Field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 7.53 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Initialize model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel size: 294.79 MB\n",
      "\u001b[32m[------------] \u001b[0mTime cost for model initial: 0.31 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to train ...\u001b[0m\n",
      "\u001b[32m[------------]\u001b[0m Epoch      Train log_loss     Time cost (sec)\n",
      "\u001b[32m[ \u001b[0m  10%\u001b[32m      ]\u001b[0m     1            0.103978                3.20\n",
      "\u001b[32m[ \u001b[0m  20%\u001b[32m      ]\u001b[0m     2            0.100063                3.34\n",
      "\u001b[32m[ \u001b[0m  30%\u001b[32m      ]\u001b[0m     3            0.096206                3.35\n",
      "\u001b[32m[ \u001b[0m  40%\u001b[32m      ]\u001b[0m     4            0.092335                3.26\n",
      "\u001b[32m[ \u001b[0m  50%\u001b[32m      ]\u001b[0m     5            0.088813                3.31\n",
      "\u001b[32m[ \u001b[0m  60%\u001b[32m      ]\u001b[0m     6            0.085909                3.35\n",
      "\u001b[32m[ \u001b[0m  70%\u001b[32m      ]\u001b[0m     7            0.083515                3.48\n",
      "\u001b[32m[ \u001b[0m  80%\u001b[32m      ]\u001b[0m     8            0.081505                3.38\n",
      "\u001b[32m[ \u001b[0m  90%\u001b[32m      ]\u001b[0m     9            0.079804                3.27\n",
      "\u001b[32m[ \u001b[0m 100%\u001b[32m      ]\u001b[0m    10            0.078298                3.35\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to save model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mModel file: models/best.out\n",
      "\u001b[32m[------------] \u001b[0mTime cost for saving model: 0.39 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Finish training\u001b[0m\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 41.60 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training best model: lambda=0.0001, dim=4\\n\")\n",
    "ffm_model = xl.create_ffm()\n",
    "ffm_model.setTrain(\"train.txt\")\n",
    "param = {\"task\": \"binary\", \"lambda\": 0.0001, \"k\": 4}\n",
    "ffm_model.fit(param, f\"models/best.out\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing best\n",
      "\n",
      "\u001b[32m\u001b[1m----------------------------------------------------------------------------------------------\n",
      "           _\n",
      "          | |\n",
      "     __  _| |     ___  __ _ _ __ _ __\n",
      "     \\ \\/ / |    / _ \\/ _` | '__| '_ \\ \n",
      "      >  <| |___|  __/ (_| | |  | | | |\n",
      "     /_/\\_\\_____/\\___|\\__,_|_|  |_| |_|\n",
      "\n",
      "        xLearn   -- 0.40 Version --\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\u001b[39m\u001b[0m\u001b[32m[------------] \u001b[0mxLearn uses 8 threads for prediction task.\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Load model ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mLoad model from models/best.out\n",
      "\u001b[32m[------------] \u001b[0mLoss function: cross-entropy\n",
      "\u001b[32m[------------] \u001b[0mScore function: ffm\n",
      "\u001b[32m[------------] \u001b[0mNumber of Feature: 1170867\n",
      "\u001b[32m[------------] \u001b[0mNumber of K: 4\n",
      "\u001b[32m[------------] \u001b[0mNumber of field: 8\n",
      "\u001b[32m[------------] \u001b[0mTime cost for loading model: 0.21 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Read Problem ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mFirst check if the text file has been already converted to binary format.\n",
      "\u001b[32m[------------] \u001b[0mBinary file (test.txt.bin) found. Skip converting text to binary.\n",
      "\u001b[32m[------------] \u001b[0mTime cost for reading problem: 0.62 (sec)\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Start to predict ...\u001b[0m\n",
      "\u001b[32m[------------] \u001b[0mThe test loss is: 0.128203\n",
      "\u001b[32m\u001b[1m[ ACTION     ] Clear the xLearn environment ...\u001b[0m\n",
      "\u001b[32m\u001b[1m[------------] Total time cost: 1.97 (sec)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "res = test_model(\"models/best.out\", \"best\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = {\n",
    "    \"ffm\": res,\n",
    "    \"linear model\": {\"log_loss\": 0.1342, \"roc_auc\": 0.7843},\n",
    "    \"baseline\": {\"log_loss\": 0.1549, \"roc_auc\": 0.5000},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_loss</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ffm</th>\n",
       "      <td>0.128</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear model</th>\n",
       "      <td>0.134</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.155</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              log_loss  roc_auc\n",
       "ffm              0.128    0.802\n",
       "linear model     0.134    0.784\n",
       "baseline         0.155    0.500"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(compare).transpose().sort_values(by=[\"roc_auc\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, нам удалось обучить факторизационную машину, которая более точно делает предсказания, чем линейная модель с предыдущего домашнего задания."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
