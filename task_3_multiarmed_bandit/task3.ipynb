{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "from scipy.stats import randint, uniform, beta\n",
    "from sim_lib import simulation\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(policy, verbose=True):\n",
    "    seed = 18475\n",
    "    np.random.seed(seed=seed)\n",
    "    start = time.time()\n",
    "    print(\"Starting to evaluate policy...\")\n",
    "    output = simulation(policy, n=200_000, seed=seed, verbose=verbose)\n",
    "    end = time.time()\n",
    "    print(f\"Evaluation is done! Total time: {end - start:.2f} seconds\\n\")\n",
    "    return {\n",
    "        \"regret\": output[\"regret\"],\n",
    "        \"mean_regret\": output[\"regret\"] / output[\"rounds\"],\n",
    "        \"total_banners\": output[\"total_banners\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом посмотрим на бейзлайн алгоритм - `e-greedy` политику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eps_greedy(history: pd.DataFrame, eps: float):\n",
    "    if uniform.rvs() < eps:\n",
    "        n = history.shape[0]\n",
    "        return history.index[randint.rvs(0, n)]\n",
    "\n",
    "    ctr = history[\"clicks\"] / (history[\"impressions\"] + 10)\n",
    "    n = np.argmax(ctr)\n",
    "    return history.index[n]\n",
    "\n",
    "\n",
    "eps_greedy_policy = partial(eps_greedy, eps=0.06)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to evaluate policy...\n",
      "\n",
      "\n",
      "Evaluation is done! Total time: 575.22 seconds\n",
      "Regret is 1540.7609683932544\n"
     ]
    }
   ],
   "source": [
    "print(f\"Regret is {policy_evaluation(eps_greedy_policy, verbose=False)['regret']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My policy - UCB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве политики я выбрала `UCB`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UCB:\n",
    "    def __init__(self, C):\n",
    "        self.C = C\n",
    "        self.calls = 0\n",
    "\n",
    "    def __call__(self, history: pd.DataFrame):\n",
    "        self.calls += 1\n",
    "        ctr = history[\"clicks\"] / (history[\"impressions\"] + 1)\n",
    "        exploration = np.sqrt(2 * np.log(self.calls) / (history.impressions + 1))\n",
    "        expectation = ctr + self.C * exploration\n",
    "        n = np.argmax(expectation)\n",
    "        return history.index[n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сначала проверим, как работает наш алгоритм с `C = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to evaluate policy...\n",
      "\n",
      "\n",
      "Evaluation is done! Total time: 531.22 seconds\n",
      "Regret is 11185.91629936366\n"
     ]
    }
   ],
   "source": [
    "print(f\"Regret is {policy_evaluation(UCB(C=1), verbose=False)['regret']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Результат не очень хороший, поэтому будем перебирать параметр `exploration`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.05, 0.1, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 531.73 seconds\n",
      "\n",
      "C = 0.0005\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 550.57 seconds\n",
      "\n",
      "C = 0.001\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 543.02 seconds\n",
      "\n",
      "C = 0.005\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 553.38 seconds\n",
      "\n",
      "C = 0.01\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 519.12 seconds\n",
      "\n",
      "C = 0.05\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 543.29 seconds\n",
      "\n",
      "C = 0.1\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 515.78 seconds\n",
      "\n",
      "C = 0.5\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 506.40 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for c in C:\n",
    "    print(f\"C = {c}\")\n",
    "    results[c] = policy_evaluation(UCB(C=c), verbose=False)[\"regret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0001</th>\n",
       "      <td>7570.250349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0005</th>\n",
       "      <td>7570.250349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0010</th>\n",
       "      <td>7570.250349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0050</th>\n",
       "      <td>7570.250349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0100</th>\n",
       "      <td>974.101387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0500</th>\n",
       "      <td>2424.896208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1000</th>\n",
       "      <td>258.315825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5000</th>\n",
       "      <td>4013.025866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             regret\n",
       "0.0001  7570.250349\n",
       "0.0005  7570.250349\n",
       "0.0010  7570.250349\n",
       "0.0050  7570.250349\n",
       "0.0100   974.101387\n",
       "0.0500  2424.896208\n",
       "0.1000   258.315825\n",
       "0.5000  4013.025866"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"regret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты интересные, для значений `C < 0.005` получились одинаковые значения регрета, лучший результат для `C = 0.1`. Не наблюдается какой-то однозначной зависимости между коэффициентом эксплорейшена и регретом.\n",
    "Возможно, слишком маленькие коэффициенты приводят к тому, что часто дергаем ручки жадно, почти не исследуем и хорошее приближение для награды получить не удается. Оптимальный эксплорейшен нужно прям поискать) Предлагается посмотреть на значения в окрестности `0.1`, поскольку с этим коэффициентом получился хороший результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [0.08, 0.09, 0.2, 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.08\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 512.52 seconds\n",
      "\n",
      "C = 0.09\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 522.49 seconds\n",
      "\n",
      "C = 0.2\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 563.35 seconds\n",
      "\n",
      "C = 0.3\n",
      "Starting to evaluate policy...\n",
      "Evaluation is done! Total time: 537.36 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "for c in C:\n",
    "    print(f\"C = {c}\")\n",
    "    results[c] = policy_evaluation(UCB(C=c), verbose=False)[\"regret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regret</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.08</th>\n",
       "      <td>197.726862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.09</th>\n",
       "      <td>228.795585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>797.937764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>1665.415854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           regret\n",
       "0.08   197.726862\n",
       "0.09   228.795585\n",
       "0.20   797.937764\n",
       "0.30  1665.415854"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"regret\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получилось улучшить результат: `regret = 198` при `C = 0.08`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
